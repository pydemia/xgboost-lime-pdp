{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: `xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env. Setting\n",
    "\n",
    "### Modules\n",
    "\n",
    "1. Module Import \n",
    "2. Version Check\n",
    "3. Font: `DejaVu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:58.460185Z",
     "start_time": "2019-05-23T06:28:57.961896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy   = 1.16.3\n",
      "pandas  = 0.24.2\n",
      "matplotlib = 2.2.4\n",
      "sklearn = 0.21.1\n",
      "xgboost = 0.82\n",
      "pdpbox  = 0.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "# from xgboost.compat import XGBLabelEncoder\n",
    "# => is IDENTICAL to `sklearn.preprocessing.LabelEncoder`\n",
    "\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "import pdpbox\n",
    "from pdpbox import pdp, info_plots\n",
    "\n",
    "\n",
    "for _pkg in [np, pd, mpl, skl, xgb, lime, pdpbox]:\n",
    "    if hasattr(_pkg, '__version__'):\n",
    "        print(f'{_pkg.__package__:<7} = {_pkg.__version__}')\n",
    "\n",
    "\n",
    "font_dict = {\n",
    "    path.split('/')[-1][:-4]: path\n",
    "    for path in fm.get_fontconfig_fonts()\n",
    "    if 'dejavu' in path.lower().split('/')[-1]\n",
    "}\n",
    "\n",
    "plt.rcParams['font.family'] = sorted(font_dict.keys(), key=len)[0]\n",
    "\n",
    "\n",
    "# os.chdir('../git/xgboost-lime-pdp')\n",
    "fpath = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:58.960316Z",
     "start_time": "2019-05-23T06:28:58.461377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: lime\n",
      "Version: 0.1.1.34\n",
      "Summary: Local Interpretable Model-Agnostic Explanations for machine learning classifiers\n",
      "Home-page: http://github.com/marcotcr/lime\n",
      "Author: Marco Tulio Ribeiro\n",
      "Author-email: marcotcr@gmail.com\n",
      "License: BSD\n",
      "Location: /home/pydemia/apps/anaconda3/envs/sparkml-xgboost-lime-test/lib/python3.6/site-packages\n",
      "Requires: scikit-image, numpy, scipy, matplotlib, scikit-learn\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes & Functions\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>$\\cdot$ `as_int`, `as_int_str`, `as_float`</b>: 데이터 load 시 Column data type 지정\n",
    "</div>\n",
    "\n",
    "```py\n",
    "col_converter = {'USE_YN': as_int_str, 'SCORE': as_float}\n",
    "data = pd.read_csv(filename, converters=col_converter, ...)\n",
    "```\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>$\\cdot$ `DataFrameImputer`</b>: 결측값 대체\n",
    "</div>\n",
    "\n",
    "```py\n",
    "data = pd.concat(...)\n",
    "data = DataFrameImputer().fit_transform(data)\n",
    "\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>$\\cdot$ `preprocess_by_column`</b>: 데이터 전처리(String Categorization 포함)\n",
    "</div>\n",
    "\n",
    "```py\n",
    "XY, col_types_dict, category_dict, float_scaler = preprocess_by_column(XY)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read_dtype_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:58.968756Z",
     "start_time": "2019-05-23T06:28:58.965191Z"
    }
   },
   "outputs": [],
   "source": [
    "def as_int(string):\n",
    "    return np.fromstring(string, dtype=np.int64, sep=',')[0]\n",
    "\n",
    "def as_int_str(string):\n",
    "    return np.fromstring(string, dtype=np.int64, sep=',').astype(np.str)[0]\n",
    "\n",
    "def as_str(string):\n",
    "    return np.fromstring(string, dtype=np.str, sep=',')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Class `DataFrameImputer`: In case of Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:58.985662Z",
     "start_time": "2019-05-23T06:28:58.970452Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "    \"\"\"Fill missing values.\n",
    "\n",
    "    Columns of dtype object are imputed with the most frequent value \n",
    "    in column.\n",
    "    Columns of other types are imputed with mean of column.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series(\n",
    "            [\n",
    "                X[c].value_counts().index[0]\n",
    "                if X[c].dtype == np.dtype('O')\n",
    "                else X[c].mean()\n",
    "                for c in X\n",
    "            ],\n",
    "            index=X.columns,\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Function `preprocess_by_column`: Column Typing & Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:59.015369Z",
     "start_time": "2019-05-23T06:28:58.993365Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_by_column(dataframe):\n",
    "    \"\"\"Column Typing & Categorization.\n",
    "\n",
    "    If a column has `float`, it will be min-max scaled.\n",
    "    If a column has `str`, it will be categorized & substitute by int, which is its code number.\n",
    "    If a column has `int`, do nothing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: pandas.DataFrame\n",
    "        Data to preprocess.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe: pandas.DataFrame\n",
    "        Preprocessed Data.\n",
    "            \n",
    "    col_dict: dict\n",
    "        A dictionary of column lists by its dtype.\n",
    "    \n",
    "    float_scaler: sklearn.preprocessing.MinMaxScaler\n",
    "        A MinMaxScaler instance of `float` type columns. \n",
    "    \n",
    "    \"\"\"\n",
    "    grouped = dataframe.columns.to_series().groupby(dataframe.dtypes).groups\n",
    "    col_types = {\n",
    "        dtype.name: colname_list.tolist()\n",
    "        for dtype, colname_list in grouped.items()\n",
    "    }\n",
    "    float_columns = col_types.get('float64', [])\n",
    "    int_columns = col_types.get('int64', [])\n",
    "    str_columns = col_types.get('object', [])\n",
    "    cat_columns = int_columns + str_columns\n",
    "\n",
    "    if bool(cat_columns):\n",
    "        dataframe[cat_columns] = dataframe[cat_columns].astype('category')\n",
    "        category_codes_df = (\n",
    "            dataframe[cat_columns].apply(lambda x: x.cat.codes)\n",
    "        )\n",
    "        category_names_df = (\n",
    "            dataframe[cat_columns].apply(lambda x: x.cat.categorical)\n",
    "        )\n",
    "        category_dict = (\n",
    "            dataframe\n",
    "            [cat_columns]\n",
    "            .agg(lambda x: [x.cat.categories.tolist()])\n",
    "            .to_dict('records')\n",
    "        )[0]\n",
    "        dataframe[cat_columns] = category_codes_df\n",
    "\n",
    "    else:\n",
    "        category_dict = {}\n",
    "\n",
    "    if float_columns is not None:\n",
    "        float_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        dataframe[float_columns] = float_scaler.fit_transform(\n",
    "            dataframe[float_columns]\n",
    "        )\n",
    "\n",
    "    col_dict = {\n",
    "        'float': float_columns,\n",
    "        'category': cat_columns,\n",
    "    }\n",
    "\n",
    "    return dataframe, col_dict, category_dict, float_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Data 선택  </b><br>\n",
    "\n",
    "<b>CASE</b> = 1 또는 2<br>\n",
    "- 1: data by .<br>\n",
    "- 2: data by ..<br>\n",
    "\n",
    "<b>COLNAMES_TO_FLIKE</b> = True 또는 False<br>\n",
    "- True : colA, colB, colC, ... -> f0, f1, f2, ...<br>\n",
    "- False: colA, colB, colC, ... -> colA, colB, colC, ...<br>\n",
    "\n",
    "해당 ARGUMENT로 데이터 선택 및 전처리<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Path (Case `1` & `2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:59.031661Z",
     "start_time": "2019-05-23T06:28:59.017924Z"
    }
   },
   "outputs": [],
   "source": [
    "CASE = 1\n",
    "COLNAMES_TO_FLIKE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:28:59.045461Z",
     "start_time": "2019-05-23T06:28:59.032733Z"
    }
   },
   "outputs": [],
   "source": [
    "if int(CASE) == 1:\n",
    "    DUMP_PATH = f'{fpath}/data/nativeBoost2'\n",
    "    train_filename = f'{fpath}/data/train_63qYitG.csv'\n",
    "    test_filename = f'{fpath}/data/test_XaoFywY.csv'\n",
    "\n",
    "elif int(CASE) == 2:\n",
    "    DUMP_PATH = f'{fpath}/data/nativeBoost6features'\n",
    "    train_filename = f'{fpath}/data/train_new.csv'\n",
    "    test_filename = f'{fpath}/data/test_new.csv'\n",
    "\n",
    "else:\n",
    "    raise ValueError('`CASE` Should be int `1` or int `2`.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:00.544155Z",
     "start_time": "2019-05-23T06:28:59.046512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Customer_Rating', 'Customer_Since_Months', 'Destination_Type',\n",
      "       'Trip_Distance', 'Type_of_Cab', 'Var3', 'Surge_Pricing_Type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if int(CASE) == 1:\n",
    "\n",
    "    int_type_colnames = ['Surge_Pricing_Type', 'Var3']\n",
    "    col_converter = {colname: as_int_str for colname in int_type_colnames}\n",
    "\n",
    "    train_df = pd.read_csv(\n",
    "        train_filename, header=0, converters=col_converter,\n",
    "    )\n",
    "    test_df = pd.read_csv(\n",
    "        test_filename, header=0, converters=col_converter,\n",
    "    )\n",
    "\n",
    "    data = pd.concat(\n",
    "        [train_df, test_df],\n",
    "        axis=0,\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    data = DataFrameImputer().fit_transform(data)\n",
    "    data = data.drop(\n",
    "        [\n",
    "            'Trip_ID',\n",
    "            'Cancellation_Last_1Month',\n",
    "            'Confidence_Life_Style_Index',\n",
    "            'Gender',\n",
    "            'Life_Style_Index',\n",
    "            'Var1',\n",
    "            'Var2',\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    y_cols = target_names = ['Surge_Pricing_Type']\n",
    "\n",
    "\n",
    "elif int(CASE) == 2:\n",
    "    int_type_colnames = ['c1', 'c2', 'c6', 'r1']\n",
    "    col_converter = {colname: as_int_str for colname in int_type_colnames}\n",
    "\n",
    "    X = train_df = pd.read_csv(\n",
    "        train_filename, header=0, converters=col_converter,\n",
    "    )\n",
    "    Y = test_df = pd.read_csv(\n",
    "        test_filename, header=0, converters=col_converter,\n",
    "    )\n",
    "    data = pd.concat([X, Y], axis=1)\n",
    "    \n",
    "    y_cols = target_names = ['r1']\n",
    "\n",
    "\n",
    "x_cols = feature_names = data.columns.drop(target_names).tolist()\n",
    "xy_cols = x_cols + y_cols\n",
    "data = data[xy_cols]\n",
    "print(data.columns)\n",
    "\n",
    "if COLNAMES_TO_FLIKE:\n",
    "    data.columns = [f\"f{i}\" for i in range(len(data.columns))]\n",
    "    y_cols = target_names = [data.columns[-1]]\n",
    "\n",
    "x_cols = feature_names = data.columns.drop(y_cols).tolist()\n",
    "xy_cols = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:00.709413Z",
     "start_time": "2019-05-23T06:29:00.545167Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f6']\n"
     ]
    }
   ],
   "source": [
    "XY, col_types_dict, category_dict, float_scaler = preprocess_by_column(data)\n",
    "\n",
    "X = source_df = XY[x_cols]\n",
    "Y = target_df = XY[y_cols]\n",
    "Y_series = target_series = Y[Y.columns[0]]\n",
    "\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pre-trained Model: `xgboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 진행 과정\n",
    "\n",
    "1. `xgb.Booster`:  \n",
    "    `predict_proba` 없음.\n",
    "<br>\n",
    "\n",
    "2. `xgb.XGBClassifier`:  \n",
    "    - `predict_proba` 결과 shape가 기대와 다름. `(4, 176426)`  \n",
    "    - `predict`는 정상적으로 출력 `(88213,)`\n",
    "\n",
    "<br>\n",
    "\n",
    "3. `xgb.XGBModel`(`xgb.XGBClassifier`의 `super class`):   \n",
    "    - `predict_proba` 대신 `predict` 활용하여 `lime`에 적용. 성공.\n",
    "      - `lime` Documentation에 classification은 `predict_proba`를 사용하라고 명시되어 있어 추가 검토 진행.\n",
    "\n",
    "<br>\n",
    "\n",
    "4. `xgb.XGBClassifier`에 계속 적용 시도, but `(4, 176426)`.\n",
    "    - Q1: 왜 Label 개수에 해당하는 axis가 4인지?: (data 내 DISTINCT COUNT는 3)\n",
    "    - Q2: 왜 `176426`인지?: data record 개수인 `88213`의 2배"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: `XGBModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:00.896784Z",
     "start_time": "2019-05-23T06:29:00.710636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBModel(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "         colsample_bytree=1, gamma=0, importance_type='gain', learning_rate=0.1,\n",
      "         max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "         n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
      "         random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "         seed=None, silent=True, subsample=1)\n",
      "X:  (219057, 6)\n",
      "Y unique:  3 [0 1 2]\n",
      "predict:  (219057, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.36621702, 0.20990732, 0.21842004, 0.20545565],\n",
       "       [0.36621702, 0.20990732, 0.21842004, 0.20545565],\n",
       "       [0.35622832, 0.20418203, 0.23973788, 0.19985178],\n",
       "       [0.36621702, 0.20990732, 0.21842004, 0.20545565],\n",
       "       [0.3837856 , 0.20408864, 0.21236539, 0.19976035]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Load a pre-trained Model ------------------------------------------------\n",
    "model = xgb.XGBModel()\n",
    "model.load_model(DUMP_PATH)\n",
    "model.n_classes_ = len(np.unique(Y.values))\n",
    "model._le = LabelEncoder().fit(np.unique(Y.values))\n",
    "\n",
    "print(model)\n",
    "print('X: ', X.shape)\n",
    "print('Y unique: ', len(np.unique(Y)), np.unique(Y))\n",
    "# print('predict_proba: ', model.predict_proba(X).shape)\n",
    "print('predict: ', model.predict(X).shape)\n",
    "model.predict(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:00.999132Z",
     "start_time": "2019-05-23T06:29:00.897654Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)\n",
      "X:  (219057, 6)\n",
      "Y unique:  3 [0 1 2]\n",
      "predict_proba:  (4, 438114)\n",
      "predict:  (219057,)\n"
     ]
    }
   ],
   "source": [
    "# %% Load a pre-trained Model ------------------------------------------------\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "model.load_model(DUMP_PATH)\n",
    "model.n_classes_ = len(np.unique(Y.values))\n",
    "model._le = LabelEncoder().fit(np.unique(Y.values))\n",
    "\n",
    "print(model)\n",
    "print('X: ', X.shape)\n",
    "print('Y unique: ', len(np.unique(Y)), np.unique(Y))\n",
    "print('predict_proba: ', model.predict_proba(X).shape)\n",
    "print('predict: ', model.predict(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test without DUMP: A New Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.012318Z",
     "start_time": "2019-05-23T06:29:01.000129Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "aa = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.018220Z",
     "start_time": "2019-05-23T06:29:01.013832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "tmp_X = pd.DataFrame(aa['data'], columns=aa['feature_names'])\n",
    "tmp_Y = pd.DataFrame(aa['target'], columns=['Y'], dtype=str)\n",
    "tmp_XY = pd.concat([tmp_X, tmp_Y], axis=1)\n",
    "\n",
    "print(np.unique(tmp_Y.values))\n",
    "print(aa['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.056740Z",
     "start_time": "2019-05-23T06:29:01.019649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "              n_jobs=1, nthread=None, objective='multi:softprob',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)\n",
      "X:  (150, 4)\n",
      "Y unique:  3 ['0' '1' '2']\n",
      "predict_proba:  (150, 3)\n",
      "predict:  (150,)\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X=tmp_X, y=tmp_Y['Y'])\n",
    "\n",
    "print(model)\n",
    "print('X: ', tmp_X.shape)\n",
    "print('Y unique: ', len(np.unique(tmp_Y['Y'])), np.unique(tmp_Y['Y']))\n",
    "print('predict_proba: ', model.predict_proba(tmp_X).shape)\n",
    "print('predict: ', model.predict(tmp_X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "`objective`<b> Parameter 차이:</b><br> \n",
    "\n",
    "iris로 만든 dummy model은 `objective='multi:softprob'`값인데,<br>\n",
    "loaded model은 `objective='binary:logistic'`로 읽어들인다.<br>\n",
    "<br>\n",
    "\n",
    "<b>Y class 개수도 3개: Load 한 Model parameter가 아님.</b><br>\n",
    ": binary classification보다는 multiclass일 것. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> spark 내에서 XGBoost 동작 시 <b><i>Dummy class 1개 </i></b>가 추가되어 학습되고,<br>\n",
    "그 결과 <b>Y Class 개수</b>가 <b>3 + 1 = 4</b> 로 보이게 됨.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to `objective`](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.111299Z",
     "start_time": "2019-05-23T06:29:01.057745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)\n",
      "X:  (150, 4)\n",
      "Y unique:  3 ['0' '1' '2']\n",
      "predict_proba:  (3, 300)\n",
      "predict:  (150,)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "              n_jobs=1, nthread=None, objective='multi:softprob',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)\n",
      "X:  (150, 4)\n",
      "Y unique:  3 ['0' '1' '2']\n",
      "predict_proba:  (150, 3)\n",
      "predict:  (150,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test: `predict_proba`.\n",
    "\n",
    "`class_probs` is equal to the result of `predict`, but\n",
    "\n",
    "if self.objective == \"multi:softprob\":\n",
    "    return class_probs\n",
    "classone_probs = class_probs\n",
    "classzero_probs = 1.0 - classone_probs\n",
    "return np.vstack((classzero_probs, classone_probs)).transpose()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for _objective in ['binary:logistic', 'multi:softprob']:\n",
    "    model = xgb.XGBClassifier(objective=_objective,)\n",
    "    model.fit(X=tmp_X, y=tmp_Y['Y'])\n",
    "    model.objective = _objective\n",
    "\n",
    "    print(model)\n",
    "    print('X: ', tmp_X.shape)\n",
    "    print('Y unique: ', len(np.unique(tmp_Y['Y'])), np.unique(tmp_Y['Y']))\n",
    "    print('predict_proba: ', model.predict_proba(tmp_X).shape)\n",
    "    print('predict: ', model.predict(tmp_X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.166037Z",
     "start_time": "2019-05-23T06:29:01.112213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBModel(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "         colsample_bytree=1, gamma=0, importance_type='gain', learning_rate=0.1,\n",
      "         max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "         n_estimators=100, n_jobs=1, nthread=None, objective='reg:linear',\n",
      "         random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "         seed=None, silent=True, subsample=1)\n",
      "X:  (219057, 6)\n",
      "Y unique:  3 [0 1 2]\n",
      "predict:  (219057, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.36621702, 0.20990732, 0.21842004, 0.20545565],\n",
       "       [0.36621702, 0.20990732, 0.21842004, 0.20545565],\n",
       "       [0.35622832, 0.20418203, 0.23973788, 0.19985178],\n",
       "       [0.36621702, 0.20990732, 0.21842004, 0.20545565],\n",
       "       [0.3837856 , 0.20408864, 0.21236539, 0.19976035]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Load a pre-trained Model ------------------------------------------------\n",
    "\n",
    "model = xgb.XGBModel()\n",
    "model.load_model(DUMP_PATH)\n",
    "model.n_classes_ = len(np.unique(Y.values))\n",
    "model._le = LabelEncoder().fit(np.unique(Y.values))\n",
    "\n",
    "print(model)\n",
    "print('X: ', X.shape)\n",
    "print('Y unique: ', len(np.unique(Y)), np.unique(Y))\n",
    "# print('predict_proba: ', model.predict_proba(X).shape)\n",
    "print('predict: ', model.predict(X).shape)\n",
    "model.predict(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>$\\divideontimes$ 정상 Load 확인 </b><br>\n",
    "\n",
    "`objective='multi:softprob'`로 Multiclass 확률을 제대로 출력할 수 있게 재정의.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`xgboost.sklearn.XGBClassifier`의 `predict`, `predict_proba` Methods 발췌:__\n",
    "\n",
    "```py\n",
    "# output_margin=False (default라 둘 다 같은 값이 들어감)\n",
    "\n",
    "def predict(...):\n",
    "    ...\n",
    "    class_probs = self.get_booster().predict(test_dmatrix,\n",
    "                                             output_margin=output_margin,\n",
    "                                             ntree_limit=ntree_limit,\n",
    "                                             validate_features=validate_features)\n",
    "\n",
    "\n",
    "    if output_margin:\n",
    "        # If output_margin is active, simply return the scores\n",
    "        return class_probs\n",
    "\n",
    "    if len(class_probs.shape) > 1:\n",
    "        column_indexes = np.argmax(class_probs, axis=1)\n",
    "    else:\n",
    "        column_indexes = np.repeat(0, class_probs.shape[0])\n",
    "        column_indexes[class_probs > 0.5] = 1\n",
    "    return self._le.inverse_transform(column_indexes)\n",
    "```\n",
    "\n",
    "\n",
    "```py\n",
    "def predict_proba(...):\n",
    "    ...\n",
    "    class_probs = self.get_booster().predict(test_dmatrix,\n",
    "                                             ntree_limit=ntree_limit,\n",
    "                                             validate_features=validate_features)\n",
    "\n",
    "    if self.objective == \"multi:softprob\":\n",
    "        return class_probs   # `iris` 결과: (150, 3)\n",
    "\n",
    "    # 문제가 되는 부분 ---------------------------------------------------------------\n",
    "    classone_probs = class_probs  # (150, 3)\n",
    "    classzero_probs = 1.0 - classone_probs  # (150, 3)\n",
    "    return np.vstack((classzero_probs, classone_probs)).transpose()  # (3, 300)\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    \"\"\"코드 해석 ===================================================================\n",
    "    binary classification일 때, 0 또는 1에 대한 확률 모두를 multiclass 확률처럼 출력하기 위한 과정 (구현 문제로 판단)\n",
    "\n",
    "    # classone_probs : 1일 확률\n",
    "    # classzero_probs: 0일 확률 (전체확률 - 1일 확률)\n",
    "    \n",
    "    return 값 해석\n",
    "    ============\n",
    "    (150, 3) 2개를 vstack해서 (300, 3)으로 만들고, transpose하여 (3, 300)으로 변환됨.\n",
    "    \n",
    "    \"\"\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    ">>> le = preprocessing.LabelEncoder()\n",
    ">>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "LabelEncoder()\n",
    ">>> list(le.classes_)\n",
    "['amsterdam', 'paris', 'tokyo']\n",
    ">>> le.transform([\"tokyo\", \"tokyo\", \"paris\"]) \n",
    "array([2, 2, 1]...)\n",
    ">>> list(le.inverse_transform([2, 2, 1]))\n",
    "['tokyo', 'tokyo', 'paris']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Proper Way: `objective='multi:softprob'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.259290Z",
     "start_time": "2019-05-23T06:29:01.166986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "              n_jobs=1, nthread=None, objective='multi:softprob',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              seed=None, silent=True, subsample=1)\n",
      "X:  (219057, 6)\n",
      "Y unique:  3 [0 1 2]\n",
      "predict_proba:  (219057, 4)\n",
      "predict:  (219057,)\n"
     ]
    }
   ],
   "source": [
    "# %% Load a pre-trained Model ------------------------------------------------\n",
    "\n",
    "model = xgb.XGBClassifier(objective='multi:softprob')\n",
    "model.load_model(DUMP_PATH)\n",
    "model.n_classes_ = len(np.unique(Y.values))\n",
    "model._le = LabelEncoder().fit(np.unique(Y.values))\n",
    "\n",
    "print(model)\n",
    "print('X: ', X.shape)\n",
    "print('Y unique: ', len(np.unique(Y)), np.unique(Y))\n",
    "print('predict_proba: ', model.predict_proba(X).shape)\n",
    "print('predict: ', model.predict(X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load 할 경우 `None`으로 남아있는 `n_classes` 강제 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.264312Z",
     "start_time": "2019-05-23T06:29:01.260195Z"
    }
   },
   "outputs": [],
   "source": [
    "model.n_classes_ = len(np.unique(Y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>$\\divideontimes$ 추가 검토사항: </b> <b>LabelEncoder 값</b>을 다시 <i>fit</i> 하는 게 아니고(Y 전체 값이 필요),\n",
    "<b>기존 spark의 <i>LabelPoint 값</i></b> 으로 활용하는 방안 고려<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sklearn.preprocessing.LabelEncoder` 설명\n",
    "\n",
    "\n",
    "\n",
    "* Prepare Data:\n",
    "```py\n",
    ">>> class_list = ['setosa', 'versicolor', 'virginica']\n",
    ">>> class_list\n",
    "['setosa', 'versicolor', 'virginica']\n",
    "```\n",
    "\n",
    "* Create a new `LabelEncoder`:\n",
    "```py\n",
    ">>> from sklearn.preprocessing import LabelEncoder\n",
    ">>> lle = LabelEncoder()\n",
    "```\n",
    "\n",
    "* Train(fit) an `LabelEncoder`\n",
    "```py\n",
    ">>> lle.fit(class_list)\n",
    "LabelEncoder()\n",
    "```\n",
    "\n",
    "* Show trained classes IN ORDER.\n",
    "```py\n",
    ">>> list(lle.classes_)\n",
    "['setosa', 'versicolor', 'virginica']\n",
    "```\n",
    "\n",
    "* Decode: From `number(int)` to `category(string)`:\n",
    "```py\n",
    ">>> lle.inverse_transform([1, 0, 2, 1])\n",
    "array(['versicolor', 'setosa', 'virginica', 'versicolor'], dtype='<U10')\n",
    "```\n",
    "\n",
    "* Encode: From `category(string)` to `number(int)`:\n",
    "```py\n",
    ">>> lle.transform(['virginica', 'setosa', 'versicolor', 'virginica'])\n",
    "array([2, 0, 1, 2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>$\\divideontimes$ LabelEncoder 해결방안: </b><br>\n",
    "Index: Value 관계를 Python Dictionary로 처리하여, 입력 순서 상관없이 Label에 숫자 지정.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.275183Z",
     "start_time": "2019-05-23T06:29:01.265206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B Grade', 'C Grade', 'A Grade']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class_dict = {\n",
    "    2: 'A Grade',\n",
    "    0: 'B Grade',\n",
    "    1: 'C Grade',\n",
    "}\n",
    "y_class_list = [\n",
    "    item[1]\n",
    "    for item in sorted(list(y_class_dict.items()), key=lambda x: x[0])\n",
    "]\n",
    "y_class_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기존 Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.287690Z",
     "start_time": "2019-05-23T06:29:01.276043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict[target_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LabelEncoder 재설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.380977Z",
     "start_time": "2019-05-23T06:29:01.288537Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument must be a string or number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/apps/anaconda3/envs/sparkml-xgboost-lime-test/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/sparkml-xgboost-lime-test/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict_keys'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0073f7e6256e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_class_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y unique: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_class_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_class_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/sparkml-xgboost-lime-test/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[1;32m    219\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/apps/anaconda3/envs/sparkml-xgboost-lime-test/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"argument must be a string or number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument must be a string or number"
     ]
    }
   ],
   "source": [
    "model._le = LabelEncoder().fit(np.unique(list(y_class_dict.keys())))\n",
    "print('Y unique: ', len(y_class_list), y_class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot: Blackbox Interpretation via `lime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.405289Z",
     "start_time": "2019-05-23T06:28:59.353Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_df = X\n",
    "input_arr = input_df.values\n",
    "category_colnames = list(category_dict.keys())\n",
    "# y_category_list = category_dict[target_names[0]]\n",
    "y_category_list = y_class_list\n",
    "\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    input_arr,\n",
    "    mode='classification',\n",
    "    feature_names=xy_cols,\n",
    "    class_names=y_category_list,\n",
    "    categorical_features=category_colnames,\n",
    "    categorical_names=category_colnames,\n",
    "    feature_selection='auto', # 'forward_selection', 'lasso_path', 'auto'\n",
    "    # kernel_width=4,\n",
    ")\n",
    "\n",
    "# Get the explanation for Logistic Regression\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=input_arr[1],\n",
    "    predict_fn=model.predict_proba,\n",
    "    labels=y_class_dict.keys(),\n",
    "    num_features=4,\n",
    "    num_samples=3000,\n",
    ")\n",
    "exp.save_to_file(f'{fpath}/lime_result.html')\n",
    "exp.show_in_notebook(show_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot: Partial Dependence via `pdpbox`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.405906Z",
     "start_time": "2019-05-23T06:28:59.406Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes, summary_df = info_plots.target_plot(\n",
    "    df=XY,\n",
    "    feature=x_cols[2],\n",
    "    feature_name=x_cols[2],\n",
    "    target=y_cols[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.406480Z",
     "start_time": "2019-05-23T06:28:59.412Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes, df = info_plots.actual_plot(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    feature=x_cols[2],\n",
    "    feature_name=x_cols[2],\n",
    "    # which_classes=None,\n",
    "    predict_kwds={},  # !This parameter should be passed to avoid a strange TypeError\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.407113Z",
     "start_time": "2019-05-23T06:28:59.417Z"
    }
   },
   "outputs": [],
   "source": [
    "pdp_isolated_tmp = pdp.pdp_isolate(\n",
    "    model=model,\n",
    "    dataset=X,\n",
    "    model_features=x_cols,\n",
    "    feature=x_cols[0],\n",
    "    n_jobs=1,\n",
    ")\n",
    "fig, axes = pdp.pdp_plot(\n",
    "    pdp_isolate_out=pdp_isolated_tmp,\n",
    "    feature_name=x_cols[:2],\n",
    "    center=True, x_quantile=True,\n",
    "    ncols=3, plot_lines=True, frac_to_plot=100,\n",
    "    plot_pts_dist=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.407684Z",
     "start_time": "2019-05-23T06:28:59.422Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes, summary_df = info_plots.target_plot_interact(\n",
    "    df=XY,\n",
    "    features=x_cols[2:],\n",
    "    feature_names=x_cols[2:],\n",
    "    target=y_cols[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.408281Z",
     "start_time": "2019-05-23T06:28:59.426Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes, summary_df = info_plots.actual_plot_interact(\n",
    "    model=model,\n",
    "    X=X,\n",
    "    features=x_cols[3:],\n",
    "    feature_names=x_cols[3:],\n",
    "    which_classes=[2, 5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.408846Z",
     "start_time": "2019-05-23T06:28:59.429Z"
    }
   },
   "outputs": [],
   "source": [
    "pdp_interacted_tmp= pdp.pdp_interact(\n",
    "    model=model,\n",
    "    dataset=X,\n",
    "    model_features=x_cols,\n",
    "    features=x_cols[:2],\n",
    "    num_grid_points=[10, 10],\n",
    "    percentile_ranges=[None, None],\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.409425Z",
     "start_time": "2019-05-23T06:28:59.432Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = pdp.pdp_interact_plot(\n",
    "    pdp_interacted_tmp,\n",
    "    feature_names=x_cols,\n",
    "    plot_type='grid',\n",
    "    x_quantile=True,\n",
    "    ncols=2,\n",
    "    plot_pdp=True,\n",
    "    which_classes=[1, 2, 3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-23T06:29:01.410021Z",
     "start_time": "2019-05-23T06:28:59.436Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = pdp.pdp_interact_plot(\n",
    "    pdp_interacted_tmp,\n",
    "    feature_names=x_cols,\n",
    "    plot_type='contour',\n",
    "    x_quantile=True,\n",
    "    # ncols=1,\n",
    "    plot_pdp=True,\n",
    "    which_classes=[1, 2],\n",
    ")\n",
    "\n",
    "error_msg = ' '.join(\n",
    "    [\n",
    "        \"TypeError:\",\n",
    "        \"clabel() got an unexpected keyword argument \",\n",
    "        \"'contour_label_fontsize'.\",\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"In case of using `matplotlib==3.x`, the following error will be shown:\",\n",
    "    f\"`{error_msg}`\",\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGBoost-Lime Py3.6 (conda env)",
   "language": "python",
   "name": "sparkml-xgboost-lime-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
